
services:
  vllm-embed-vl:
    image: vishva123/vllm-server-cuda-12.8.1
    container_name: vllm-embed-vl

    ports:
      - "8282:8282"

    ipc: host

    ulimits:
      memlock: -1
      stack: 67108864

    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: -1
              capabilities: [gpu]

    volumes:
      - ./Models:/root/.cache/huggingface

    command: >
      Qwen/Qwen3-VL-Embedding-2B
      --host 0.0.0.0
      --port 8282
      --runner pooling
      --convert embed
      --hf-overrides '{"is_matryoshka":true,"matryoshka_dimensions":[768,1024,2048]}'
      --max-model-len 8192
      --gpu-memory-utilization 0.70
      --enforce-eager

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:1234/health"]
      interval: 15s
      timeout: 5s
      retries: 20
      start_period: 60s

