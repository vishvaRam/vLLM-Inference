services:
  vllm-ocr:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vllm-ocr
    ports:
      - "2323:2323"

    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
      
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: -1
              capabilities: [gpu]

    command: >
      /models/llm
      --host 0.0.0.0
      --port 2323
      --max-model-len 32k
      --kv-cache-dtype auto
      --gpu-memory-utilization 0.60
      --enable-chunked-prefill
      --enable-prefix-caching
      --max-num-batched-tokens 16000
      --disable-log-requests
